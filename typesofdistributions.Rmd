---
title: "Probability Distributions in R"
author: "Serdar Korur"
date: "12/3/2019"
output: html_document
---

Probability distributions describe what we think the probability of each outcome is, which is sometimes more interesting to know than simply which single outcome is most likely. 

We've used pre-existing knowledge about RNA-seq data to design a statistical model of the process and draw inference to estimate unknown parameters in the model from the data.

# Extras 

Extras:
The sum of all the probabilities must be equal to one. And the nature of the variable determines the shape of the probability distribution.
Terminology:
A statistical model is a family of distributions. Model is a statistical hypothesis.What does model parameters mean?

What is the difference between Statistical inference and probability?

Statistical inference --> You have some observed data   ---> Build a model

Probability --> is the study of what kind of data can be generated from a model?

In probability theory we consider some underlying process which has some randomness or uncertainty modeled by random variables, **and we figure out what happens.**


I like the example of a jar of red and green jelly beans.

**A probabilist starts by knowing the proportion of each and asks the probability of drawing a red jelly bean.**  A statistician infers the proportion of red jelly beans by sampling from the jar.

Probability and Statistical inference are two related areas of mathematics whose concern is the relative frequency of events. 

Probability deals with predicting future events from a given model, whereas statistical inference analyses the frequency of past events. 

Probabiliy is theoretical wheras statistics is applied, in order to make sense of real world. 

--ed Both subjects are important and useful. 

--ed probability theory allows us to find the consequences in the ideal world, and statistics allows us to find out how ideal the world is. 

--ed You can express uncertainty about any variable by using a probability distribution. You can select a distribution based on available data, on the judgment of a knowledgeable expert, or on a combination of data and judgment.


--ed Statistical inference deduces the properties of an underlying probability distribution.

Statistical inference makes propositions about the population or about the world. 

In probability we know how the world look like and we use this knowledge to estimate future events. 

They are complementary approaches.

---ed A probability distribution gives all the information about how a random quantity fluctuates. In practice we usually do not have the full probability distribution of our quantity of interest. We may know or assume something about it without knowing or assuming that we know everything about it. For example, we might assume that some quantity is normally distributed but know nothing about the mean and variance. Then we have a collection of candidates for the distribution to choose from; in our example, it is all possible normal distributions. **This collection of distributions forms a statistical model.** We use it by gathering data and then restricting our class of candidates so that all the remaining candidates are consistent with the data in some appropriate sense.

--ed **Firstly, we must understand that statistics and statistical models are not the same. Statistics is the mathematical study of data. You cannot do statistics unless you have data. A statistical model is a model for the data that is used either to infer something about the relationships within the data or to create a model that is able to predict future values. Often, these two go hand-in-hand.**

--ed **e.g linear model the point of our model is to characterize the relationship between the data and our outcome variable**

--ed **Two major goals in the study of biological systems are inference and prediction. Inference creates a mathematical model of the data-generation process to formalize understanding or test a hypothesis about how the system behaves. Prediction aims at forecasting unobserved outcomes or future behavior, such as whether a mouse with a given gene expression pattern has a disease. Prediction makes it possible to identify best courses of action (e.g., treatment choice) without requiring understanding of the underlying mechanisms. In a typical research project, both inference and prediction can be of value—we want to know how biological processes work and what will happen next. For example, we might want to infer which biological processes are associated with the dysregulation of a gene in a disease, as well as detect whether a subject has the disease and predict the best therapy.**

https://www.nature.com/articles/nmeth.4642?source=post_page-----64b49f07ea3----------------------

# In the light of the above, Probability uses probability distributions to find the consequences of the events in the ideal world. Whereas statistics tries to fit observations to a given probability distribution. 


uses probability distributions to compare 

the frequency of the past events





# Why do we need probability distributions in the first place?

Different pobability distributions account for different nature of the underlying data. For example anova vs students-t test, uses F and t distrbution respoectively. 

--ed In statistics, you have to determine if the pattern you identify in the data is significantly different from no pattern at all. There are a bunch of ways to do this, but the most common is the use of probability functions. Probability functions permit you to determine the chance that your model is different. Among the several probability functions, the F-distribution rises to the top a lot. So let’s take a glance at the F-distribution. What is the F-distribution
A probability distribution, like the normal distribution, is means of determining the probability of a set of events occurring. This is true for the F-distribution as well.

The F-distribution is a skewed distribution of probabilities similar to a chi-squared distribution. But where the chi-squared distribution deals with the degree of freedom with one set of variables, **the F-distribution deals with multiple levels of events having different degrees of freedom.** This means that there are several versions of the F-distribution for differing levels of degrees of freedom.

https://magoosh.com/statistics/f-distribution-explained/

--> We have some data from a sample. To model the data. 

We want to know our population parameters?
We want to know whether two samples come from same populations?
We want to calculate p value for an event?
We want to generate data
We want to calculate probability for an observation?
You can use probability densities to identify which data the certain is coming from? (Iris, species types)

Univariate probability distributions:

1. Normal distribution
2. Binomial distribution
3. Multinomial distribution
3. Poissson distribution
4. Expontential distribution
The exponential distribution should come to mind when thinking of “time until event”, maybe “time until failure.”
5. Geometric distribution
6. Gamma distribution



--ed If the binomial distribution is “How many successes?” then the geometric distribution is “How many failures until a success?”
The negative binomial distribution is a simple generalization. It’s the number of failures until r successes have occurred, not just 1.

Multivariate probability distributions:


# Multivariate distribution

Multivariate distributions is used to describe probability distributions of more than one variable at the same time allowing us to see the relation between them. 

ed-- In modern time, the multivariate normal distribution is incredibly important in machine learning, whose purpose is (very roughly speaking) to categorize input data xx into labels yy, based on some training pairs x,yx,y. **One major approach involves analyzing the distribution p(x|y)p(x∣y), and approximating it with a multivariate normal distribution, the validity of which can be checked using various normality tests; paradoxically, however, classifying based on multivariate normal distributions has been successful in practice even when it is known to be a poor model for the data.**

### When we need them?

In hypothesis testing, clustering, and likelihood calculation, you need
to calculate the density of a specified multivariate normal distribution

Student courses, does physics correlates with math results or art with english.

### Mean vector

Since there are more than one variable mean is not a single value but a vector with the length of number of variables

### variance-covariance matrix

**Variance** is the average of the squared differences from the Mean and
we use variance to describe the spread the a univariate distribution and variance-covariance matrix to describe the spread of multivariate data. 

**relation**
sd to variance
correlation to covariance

### Why we need a Variance-Covariance matrix

**Variance and covariance matrix** is used to store the spread parameters of a multivariate data. 
Variances of individual random variables appear at the diagonal and covariances appear in the off-diagonal elements. 

Covariance represents the product of the differences of two variables from their mean. It measures how two variables of a data move together. 

when we standardise the covariance of two variables by dividing with the product of their individual standard deviations we get the correlation value.

>>Formula..


var() is used to calculate variance co variance matrix.
cor() is used to calculate correlation matrix
corrplot()
### What is the difference between univariate data vs multivariate data?

Univariate distributions a
Univariate normal vs multivariate normal

### R functions for multivariate data

library(mvtnorm)
rmvnorm(n, mean , sigma)

rnorm rmvnorm rt rmvt
qnorm
dnorm
pnorm
## Definitions

### Variance-Covariance matrix
###  Correlation matrix

## Plotting multivariate variables
pairs()
splom()
ggpairs()
scatterplot3d()

$$\sum_{i=1}^n X_i$$
$$E[X{i}-\hat X][Y-\hat Y] $$

$$Var(X) =\sum_{}(X{i}-\hat X)^2/N$$
# Code for plotting bivariate densities
```{r}
# Create grid
d <- expand.grid(seq(-3, 6, length.out = 50 ), seq(-3,  6, length.out = 50))                   

# Calculate density on grid
dens1 <- dmvnorm(as.matrix(d), mean=c(1,2), sigma=matrix(c(1, .5, .5, 2), 2))

# Convert to matrix 
dens1 <-  matrix(dens1, nrow = 50 )

# Use perspective plot
persp(dens1, theta = 80, phi = 30, expand = 0.6, shade = 0.2, 
        col = "lightblue", xlab = "x", ylab = "y", zlab = "dens")
```


#### What is Kurtosis?

Kurtosis is a statistical measure that defines how heavily the tails of a distribution differ from the tails of a normal distribution. In other words, kurtosis identifies whether the tails of a given distribution contain extreme values.

# Cumulative Distribution


# Multivariate Statistical techniques (that assume multivariate normality)

* multivariate regression
* discriminant analysis
* model-based clustering
* principal component analysis (PCA)
* multivariate analysis of variance (MANOVA)

**qqnorm** is widely used to test univariate normality. ( Created by plotting theoretical quantiles to the sample quantiles)

Calculate univariate normality of each variable in the data
### Multuvariate normality tests

# newer version does not work.
install.packages("devtools")
library(devtools)
install_version('MVN', '4.0.2')

### qqnorm of all variables

uniPlot(diabetes[,1:9])

#### Check multivariate normality

mardiaTest(diabetes[, 1:8])

#### Multivariate normal distribtuions use cases in machine learning

https://brilliant.org/wiki/multivariate-normal-distribution/

### e.g Anomaly detection???

### Other types of multivariate distributions

Not all multivatiate processess follow multivariate normal

multivariate-t distribtuion
skewed-normal-multivariate
skewed-t-multivariate

mean: is the location parameter
variane: is the scale parameter

normal vs t compared

Distribution	Probability
Normal	0.05
t(df=1)	0.3
t(df=8)	0.0857
t(df=20)	0.0641
t(df=30)	0.0593

R Functions for multivariate t distributions (delta,sigma)
rmvt
qmvt
dmvt
pmvt

## In the stock market, individual stocks are modeled my univariate t distribution
due to the volatility of prices
if you want to model 3 stocks, you need a multivatiate t distribution

## Calculating the density of a multivariate distribution on a grid
```{r}
x <- seq(-3, 6, by = 1); y <- seq(-3, 6, by = 1)
d <- expand.grid(x = x, y = x)                   
del1 <- c(1, 2); sig1 <- matrix(c(1, .5, .5, 2), 2)
dens <- dmvt(as.matrix(d), delta = del1, sigma = sig1, df = 10, log = FALSE)
scatterplot3d(cbind(d, dens), type = "h", zlab = "density")
```

### Skewed multivatiate

Both normal and t distributions are designed to model symetric distr.b
but real data is often skewed.

# Functions for skewed normal distribution

SN library
dmsn
pmsn
rmsn
need to specify(xi, omega, alpha)
xi is the location parameter, mean
omega is the scale parameter, variance, covariance
alpha= is the skweness parameter

# functions for skewed-t-distribution

dmst
pmst
rmst
Need to specify xi, Omega, alpha, nu (degrees of freedom)

## plot skewed-t-dist

# Specify xi, Omega and alpha
# Specify xi, Omega and alpha
xi1 <- c(1, 2, -5) 
Omega1 <- matrix(c(1, 1, 0,
                   1, 2, 0,
                   0, 0, 5), 3, 3)
alpha1 <- c(4, 30, -5)

# Generate samples
skew.sample <- rmsn(n = 2000, xi = xi1, Omega = Omega1, alpha = alpha1)

Estimation of parameters from data
Need iterative algorithm to estimate the parameters of a skew-normal distribution

No explicit equation to calculate parameters
Several functions in sn package, including msn.mle() function

## PCA: Why we need principal component analysis

Large number of strongly correlated variables, this poses

Computational challenges
and results are hard to interpret

to avoid this ds often choose to work with relevant but uncorrelated variables. 
weighted sums of existing variables.

princomp() calculates, principal components in the data. 

# Calculate PCs
pca.state <- princomp(state.x77, cor = TRUE, scores = TRUE) 

# Plot the PCA object  
plot(pca.state) 

# Print the summary of the PCs
summary(pca.state) 

## Find the Principal compoments needed to explain a certain level of variation in the data
Cumulative proportion

# Variance explained
pc.var <- cars.pca$sdev^2

# Proportion of variation
pc.pvar <- pc.var / sum(pc.var)

# Cumulative proportion
plot(cumsum(pc.pvar), type = 'b')

# Draw screeplot
screeplot(pca.state, type = "l")
grid()

# Quickly visualize first 2 principal components with bi plot

Calculating, visualizing and intrepreting scores
biplot(cars.pca, col = c("steelblue", "white"), cex = c(0.8, 0.01))

Plotting the PC scores in two dimensions is one way to visualize high dimensional data.

# Using factoextra library for visualizing PCA components


The factoextra library provides a number of functions which make it easy to extract and visualize the output of many exploratory multivariate data analyses, including PCA. In this exercise, you will use several functions to visualize the scores and PC loadings of the state.x77 dataset.

_Use the output of princomp() function_

# Plot the scores
fviz_pca_ind(pca.state)

# Plot the PC loadings
fviz_pca_var(pca.state)

# Create a biplot
fviz_pca_biplot(pca.state)


## Multi-dimensional scaling

Another way of dimension reduction. to provide visual representation

cmdscale(distance matrix, k=max dimension, ...)

## Multidimensional scaling in more than two dimensions
cars.dist <- dist(mtcars)
cmds3 <- data.frame(cmdscale(cars.dist, k = 3))
scatterplot3d(cmds3, type = "h", pch = 19, lty.hplot = 2, color = mtcars$cyl)

## Parameter estimation for multivariate skew-normals

Unlike multivariate normal, where the parameters estimates can be obtained using the sample mean and sample variance-covariance matrix, the parameters of the skew-normal distribution need to be estimated by an iterative process. You can make use of existing functions in the sn packages to get the estimates.


_________________________________________________________________________
=========================================================================
_________________________________________________________________________
# Sources:

Variance-co variance matrix

# https://stattrek.com/matrix-algebra/covariance-matrix.aspx

R Markdown for formulas
https://www.statpower.net/Content/310/R%20Stuff/SampleMarkdown.html


https://www.stat.ncsu.edu/people/davidian/courses/st732/notes/chap3.pdf
